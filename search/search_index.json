{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sup Folks!","text":"<p>I'm an AI Engineer, and AI instructor at O'Reilly Media, I like writing about building cool tools.  A few years ago, after spending some time as a research assistant at the Champalimaud Foundation, I pivoted to industry and started working as an AI engineer, and now I help people develop AI models, tools, and all sorts of fun stuff.</p> <p>From time to time I also do some neat workshops about stuff I find interesting in AI.</p> <p>Subscribe to my Newsletter</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"posts/2025-02-16-blog-post-2/","title":"Using AI to Build Practice","text":"<p>So, these are a few examples on how one can use AI to do what I like to call building practice.</p> Building Practice <p>Building practice is about systematically tackling a desired skill like 3d printing, playing the piano and so on, through the process of building a system that involves a closed looop environment for improving particular aspects of that skill.</p>"},{"location":"posts/2025-02-16-blog-post-2/#fetching-data-from-documents","title":"Fetching data from documents","text":"<p>Document-based learning can be enhanced by uploading technical PDFs and instructing the model to answer questions specifically from that content, with references to exact pages. This creates a focused learning loop for understanding specific software functions or technical concepts. The model can also help locate relevant information online through a search action that can potentially save a lot of time on manual searches across multiple URLs.</p>"},{"location":"posts/2025-02-16-blog-post-2/#breakdown-pattern","title":"Breakdown pattern","text":"<p>One fundamental pattern is what I call the breakdown pattern where you feed the model your ultimate goal and ask it to break it down into smaller, more manageable tasks or projects. </p> <p>This creates a natural progression from simple to complex challenges, allowing you to build the necessary skills incrementally while maintaining an optimal balance of difficulty at each step.</p>"},{"location":"posts/2025-02-16-blog-post-2/#suggestion-pattern","title":"Suggestion pattern","text":"<p>To complement this approach, the suggestion pattern helps maintain momentum in your learning journey. When you're unsure what to tackle next, you can describe your current skill level and completed projects to the model, which can then suggest appropriate next steps. This eliminates friction in decision-making and keeps you moving forward in your skill development.</p>"},{"location":"posts/2025-02-16-blog-post-2/#real-time-assistance","title":"Real-time assistance","text":"<p>Real-time assistance when learning a new software tool for example you can use something like Google AI Studio's real-time screen-sharing feature with Gemini to navigate complex software interfaces like AutoDesk Fusion 360. </p> <p>While not perfect, the model can provide helpful guidance and suggestions for navigating complicated user interfaces. There are some cool experimental features being built on top of this like this Gemini Cursor.</p> <p>There are also other interesting approaches related to this concept and the idea of computer use like the new tool from Microsoft: OmniParser 2.</p> <p>More gemini-based apps can be found here: Awesome-Gemini-Apps.</p>"},{"location":"posts/2025-02-16-blog-post-2/#brainstorming","title":"Brainstorming","text":"<p>Brainstorming with AI becomes more effective when you carefully craft your prompts to receive specific, targeted interactive feedback. Rather than accepting vague advice from a generic conversation, you can structure the interaction to get precise, actionable information in your preferred format. For example, when practicing writing you might want the model to be more tuned to a certain style of writing like technical, or screenwriting and so on.</p>"},{"location":"posts/2025-02-16-blog-post-2/#planning-learning-goals","title":"Planning learning goals","text":"<p>AI can also assist with planning by helping organize tasks around existing commitments and limitations. This extends beyond skill development to general productivity, allowing you to optimize your learning schedule and maintain steady progress.</p> <p>You can prompt the model to breakdown a specific goal with a certain deadline into a set of tasks that should be executed within some pre-defined schedule (that could also be given by the model).</p>"},{"location":"posts/2025-02-16-blog-post-2/#maintaining-flow","title":"Maintaining flow","text":"<p>The overarching principle in using AI for skill development is maintaining flow state. It's crucial to avoid treating AI as a gimmick and instead craft specific, ultra-specialized interactions that provide exactly what you need. The goal isn't to replace your cognitive effort but to facilitate it. </p> <p>By developing small-scale closed learning loops with clear feedback mechanisms, you create an environment where AI enhances rather than substitutes for your learning process.</p> <p>This focused approach ensures that your interaction with AI directly supports your skill development while keeping you actively engaged in the learning process.</p>"},{"location":"posts/2025-03-08-blog-post-3/","title":"An Audio-based AI-co-writing workflow","text":""},{"location":"posts/2025-03-08-blog-post-3/#step-1-download-superwhisper-for-audio-transcription","title":"Step 1 - Download Superwhisper for Audio Transcription:","text":"<ul> <li>For IOS Users</li> </ul> <p>Superwhisper allows users to dictate thoughts and ideas, transforming them into structured text. This hands-free approach enables brainstorming sessions during activities like walking or commuting.  </p>"},{"location":"posts/2025-03-08-blog-post-3/#step-2-use-chatgpt-for-idea-expansion-and-structuring","title":"Step 2 - Use ChatGPT for Idea Expansion and Structuring:","text":"<ul> <li>Download the ChatGPT app on the APP Store</li> </ul> <p>ChatGPT assists in organizing, expanding, and refining transcribed ideas. With a ChatGPT Plus subscription, users gain access to advanced features, enhancing the creative writing process.</p>"},{"location":"posts/2025-03-08-blog-post-3/#step-3-integrate-transcriptions-into-chatgpt-for-refinement","title":"Step 3 - Integrate Transcriptions into ChatGPT for Refinement","text":"<ul> <li>Import the transcribed content from Superwhisper into ChatGPT.</li> <li>Use ChatGPT to brainstorm, reframe, and expand upon the initial ideas, structuring them into coherent narratives or chapters.</li> </ul>"},{"location":"posts/2025-03-08-blog-post-3/#step-4-review-drafts-during-activities","title":"Step 4 - Review Drafts During Activities","text":"<ul> <li>Convert drafts into audio formats to listen during walks or other activities.</li> <li>You can do that with apps like speechify</li> <li>Note down feedback, ideas, or areas of improvement during these sessions (you can do it all with audio using super whisper or recording on your phone using the Iphone default voice memo app or something similar)</li> </ul>"},{"location":"posts/2025-03-08-blog-post-3/#step-5-incorporate-feedback-into-revisions","title":"Step 5 - Incorporate Feedback into Revisions","text":"<ul> <li>Input the gathered feedback into ChatGPT to refine and enhance the drafts.</li> <li>Repeat this iterative process until the desired quality is achieved.</li> <li>At this stage compile insights as bites into something like a notes app or doc.</li> </ul>"},{"location":"posts/2025-03-08-blog-post-3/#step-6-finalize-and-share","title":"Step 6 - Finalize and Share","text":"<ul> <li>Once satisfied, compile the chapters or sections into a complete manuscript.</li> <li>Share the final version with peers, editors, or publish as desired.</li> </ul>"},{"location":"posts/2025-03-08-blog-post-3/#example-walkthrough","title":"Example Walkthrough","text":"<ol> <li>Open SuperWhisper on your phone (step 3)</li> <li>Dictate your thoughts about what you want to write about or expand (make these dictations small less than a minute) (step 3)</li> <li>Copy paste that into ChatGPT with a Prompt that gives it the context of what you want to do for example you can prompt ChatGPT with this: (step 3) <pre><code>I\u2019m going to brainstorm plot ideas for a space opera novel. Please take everything I say, focusing on key characters, main conflict, and potential locations. At the end, organize the notes into a simple bullet list with headings for Characters, Conflict, and Setting.\n\n{{PASTE YOUR AUDIO TRANSCRIBED FROM SUPERWHISPER HERE}}\n</code></pre></li> <li> <p>Take that output and reflect on it (perhaps during another walk?) and if you want to expand on it you can use the feature \"Advanced Voice Mode\" from ChatGPT directly on your phone to 'talk' to ChatGPT about those ideas. (step 3-4-5)</p> </li> <li> <p>Do this in a loop:</p> </li> <li>Record your thoughts with superwhisper</li> <li>Copy paste that into ChatGPT with some input for how you want to process those 'raw thoughts'<ol> <li>It can be like 'Structure this into bullet points'</li> <li>But also something like: 'Can you rephrase these ideas?'</li> <li>You can do whatever! Be creative</li> </ol> </li> <li>Take whatever output you get back as your starting point for the next part (always working in small gradual reflexive steps)</li> <li>Copy paste the main insights into something like a google doc or your notes app to keep track of insights as bites of thoughts that will be later compiled into something like a full blog post, chapter, etc...</li> <li>Iterate until you have a draft (that usually is a bunch of rich insightful notes inside ChatGPT or that you copy pasted from there into some notes app or doc)</li> </ol>"},{"location":"posts/2025-03-22-ai-tools-life-thoughts-2025/","title":"AI Tools, Life, Travel &amp; Thoughts","text":"<p>In this post I just want to talk a little bit about some of the stuff I've been doing, what I've been 'working on', some AI tools I've been playing around with and some other stuff.</p>"},{"location":"posts/2025-03-22-ai-tools-life-thoughts-2025/#ai-tools-cursor","title":"AI Tools - Cursor","text":"<p>This year I've been using Cursor more and more, I've been following in love with the process of finding new avenus of leveraging LLMs in new and exciting ways. On the one hand I carry a bit of that fear of never being able to code again without some AI hanging over me, on the other, building things through conversation can be quite exciting. </p> <p>Even as I write this post I'm thinking! \"Hey, I don't have a simple automation to create a references section for my article!\". Then, immediately I already think: \"Ah, never mind, I can just ask Cursor to generate that when I'm done writing.</p> <p>Cursor is cool, and these are some of the things I've been getting more interested lately and intend to explore:</p>"},{"location":"posts/2025-03-22-ai-tools-life-thoughts-2025/#1-cursor-rules-files","title":"1. Cursor rules files","text":"<p>These are like files you can easily create <code>.cursorrules</code> and then inside you describe how Cursor should behave within the scope of a project.</p> <p>The cool thing is that you can make it even better by creating a folder on your root like: <code>.cursor/rules</code>, and then inside you can write spefications per programming language or file type, its bananas.</p>"},{"location":"posts/2025-03-22-ai-tools-life-thoughts-2025/#2-cursor-agentic-mode","title":"2. Cursor Agentic Mode","text":"<p>It's been fun to watch Cursor building whatever I want by just asking, then see the whole process unwind in front of me as if I'm some sort of low budget god of silly little apps.</p>"},{"location":"posts/2025-03-22-ai-tools-life-thoughts-2025/#3-mcp-cursor","title":"3. MCP + Cursor","text":"<p>I'll be honest, this is one of those that I haven't fully explored yet, essentially MCP came out and took the AI engineering world by storm. I haven't studied it in full yet, but essentialy its a standardization of what previously was simply LLM + tool calling in the wild. Now we have something more like a standard to follow to connect LLMs to tools, resources and prompts, and the promise seems to be quite exciting.</p>"},{"location":"posts/2025-03-22-ai-tools-life-thoughts-2025/#ai-tools-aider-claude-code-building-rust-apps","title":"AI Tools - Aider, Claude-code, Building Rust apps","text":"<p>Another fun things I've been doing lately is attempting to replace doom scrolling with what I think I'll start calling 'doom app creating' which essentially means talking to aider via its really neat <code>/voice</code> mode and essentially just ask it to build whatever is in my mind.</p> <p>What fascinates me more about this approach is how \"un-creative\" I can be, which I know, sounds kind of self-deprecating, but it does piss me off, like I am living in the most creative-friendly era in history and all I can come up with is like 'a todo-list with some fun interactive animations'? God damn...Davinci would have been very disappointed. </p> <p>Nevertheless, some times I have my moments and I think I come up with ideas that could at least have some potential, if it wasn't for me abandoning them immediately after I build a first 'barely functional' version of it. Some of the highlights for this week built with either Cursor or aider were:</p> <ol> <li> <p>Silly todo-list with rust (yes I built a todo list leave me alone)</p> <p></p> </li> <li> <p>A 'barely working' clipboard manager</p> <p></p> </li> <li> <p>A completely useless markdown note taking app (again why? It is beyond me at this point)</p> <p></p> </li> <li> <p>The worst 'Focus App' ever (essentially a timer with a dot in the middle for you to 'focus') </p> </li> <li> <p>A template generator app to leverage llms to iterate on templates for very precise/structured command generation (this one I think had some future!)</p> <p></p> <p>The idea here I think was actually interesting, essentially today it is super easy to generate like big terminal commands with LLMs, and I wanted to have like a super sleak, easy to use tool that would give me a minimal interface allowing to iterate on a certain structured command like the one in the image above. However, I tend to leave these silly little projects behind...but at least I wrote this little piece on it so it won't be completely forgotten.</p> </li> <li> <p>App to highlight code on the specific parts to edit given a prompt (again I liked this one!).     Again with this one, even though obviously you get this type of functionality in any IDE these days, I wanted something easy that works well in the terminal and again, it was just a minute with Cursor to have a perfectly functional version! Also, I am really interested in like ways to leverage AI to visualize stuff better so this was actually the first app I made with that concept in mind. </p> </li> <li> <p>App that allows you to navigate highlighted portions of a text     The idea here was that, since now it's so easy and fast to use embeddings (even in the terminal!) to select parts of a large text given some input (like a question, or a semantic request like 'the tools used in this paper'), I wanted to have a simple and easy to use interface to navigate those portions of the text once the relevant sections were extracted. Still have some faith for this project....</p> </li> </ol> <p>There are so many more but I think those are enough to pain the picture of the mess that is my 'random-apps' folder. Some of them were built with <code>aider</code> some with the new <code>claude-code</code>, all of them were built kind of without strong intentions, just as a exercise on chaotic experimentation.</p> <p>Now, one last note I'll say on this topic is the revolutionary change on my workflow and day-to-day by integrating llms in the terminal using SImon Willison's LLM-CLI. I can now write commands like:</p> <p><pre><code>`for f in *.txt; do echo ${f%.txt}.pdf &gt;&gt; file_classification.txt; cat $f | llm 'Give this file a one sentence description' &gt;&gt; file_classification.txt\n</code></pre> Which for me, has been the most fun I've had with AI besides what I'm about to tell you in the end of this article ;) .</p>"},{"location":"posts/2025-03-22-ai-tools-life-thoughts-2025/#ai-tools-llm-htmljs-apps","title":"AI Tools - LLM + HTML/JS Apps = \u2764\ufe0f","text":"<p>One combination I've found to work really well for a lot of stuff is to combine a powerful code model like Claude-3.7-sonnet, and then ask it to generate an app in pure html/js combined with this idea of splitting the logic of the code itself from the logic of the data (something that a lot of developers would be like 'seriously? Now you see the value of that? Oh wow!' but hey! I'm new-ish at this ok?). </p> <p>What you get is the ability to make apps that have 0 dependencies, can run directly on your browser and just works, so its like...whatever app you use that is simple enough can probably be replaced by a prompt,, 15 minutes and a cup of coffee ;).</p> <p>My biggest sucess with this combination was to write this quiz app in a single <code>.html</code> file that I use to test myself on different subjects. </p> <p>To say it has a 'simple interface' it would be an understatement, its as plain as it gets: </p> <p></p> <p>I load the questions in the right format (almost always generated by AI ;)) and then I quiz myself on whatever. The biggest use I had was to prepare for a 'The Office' themes quiz night at a bar here in Lisbon (hey we got 2<sup>nd</sup> place ok! B) ).</p> <p></p> <p></p> <p></p> <p>I've made some upgrades to this app but I haven't pulled the trigger yet because I love the simplicity of this current version.</p> <p>What I love the most about this is to be able to think of something that could be small and simple, yet powerfullly useful and effective for my current needs and workflows, and then just make it, and then use it! How cool is that?</p> <p>I even made a course that I teach live at the O'Reilly platform where I talk about this subject and I generally use this quiz app example as one of the study cases. Here is the course if you're interested:</p> <ul> <li>Building Simple Web Apps with AI Tools</li> </ul> <p>There is a lot to develop for this course still but I am excited for the next iteration of it coming up this year.</p>"},{"location":"posts/2025-03-22-ai-tools-life-thoughts-2025/#some-personal-stuff","title":"Some Personal Stuff","text":"<p>Ok, to be quick, let's list a few things that I think were good this year:</p> <ol> <li>LangChain Retweeted my article about building LLM agents in 3 levels of complexity (it got over 30.3k views!)</li> <li>I hosted my very first in-person AI Tools Workshop! This first iteration was about tools for filmmaking. I could have done a better job with the structure, but overall people really liked it and I think it was packed with actionable tips and practically insightful ideas. </li> <li>I've been working on my new workshop that I intend to publicize soon about AI tools for studying, learning and research with a focus on actually helping students and researchers to get the most out of AI without having to necessarily off load all the cognitive load and the effort of something to the AI.</li> <li>I also had my first 2 potential AI clients this year which is super exciting, both were related to building agents so that's something I'll probably be focusing this year.</li> <li>I had even more courses approved at OReilly where I currently teach a variety of online courses about LLMs, Agents and so on. The list is below if you want to check them out:<ol> <li>Using AI Tools and Python to Automate Tasks</li> <li>Building AI Apps with Gemini 2.0</li> <li>Working with o1, DeepSeek, and Gemini 2.0 Reasoning Capabilities</li> </ol> </li> </ol> <p>I also have 2 other courses right now in the works that I hope will be live in the second half of this year.</p> <ol> <li> <p>Working remote has its perks, one of which is travelling whenever I want! This year I've been to a few places already:</p> <ol> <li>Netherlands</li> <li>London</li> <li>Ireland</li> <li>Italy (Venice, Verona, Milan)</li> <li>Switzerland (spent a day in Zurich! :))</li> </ol> <p> </p> </li> </ol>"},{"location":"posts/2025-03-22-ai-tools-life-thoughts-2025/#final-thoughts-on-working-in-ai","title":"Final Thoughts on Working in AI","text":"<p>It has been a bit surreal, over these past 2 years, how my life changed completely because of AI. Like if only I knew how right my decision was to leave Brazil and come to Europe to pursue it. </p> <p>I remember it like it was yesterday, my excitement when I first started working at the Champalimaud Foundation, considered to be a world class lab for contributions to artificial intelligence I felt like that experience was going to shape my upcoming years, like my life was about to radically change, and indeed it happened! Even tough I didn't pursue a PhD in the lab, having finished my masters there and then having worked there as a hired research assistant (working on an application of generative adversarial networks to neuroscience settings) really helped me understand the inner workings of AI, how to use it, and how to get the most out of it.</p> <p>Now, working as an AI engineer, freelancer, AI instructor, everything seems quite magical, like sometimes I have to pinch myself because it feels unreal that I get paid to do the kind of stuff I get paid to do.</p> <p>From now on I'll be focusing more on producing higher technical quality content on Youtube, pursue more clients as a freelancing AI engineer, and continue to produce courses with OReilly as well as on my own, I can't wait for what's next :).</p>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/","title":"Reasoning Models, When to Use Them? What Are They Good for?","text":""},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#whats-a-reasoning-model","title":"What's a Reasoning Model?","text":"<p>I guess I want to start this conversation by defining what a thinking/reasoning model is. The easiest way to define it is that it is a model specially trained and designed for thinking through problems. </p> <p>Now, the more elaborate way of going about this definition is to look into the information we have about what differs between these models and the traditional models we are used to like ChatGPT or Claude.</p> How Reasoning models differ from Traditional LLMs <p>Reasoning models differ from traditional LLMs in several key ways:</p> <ul> <li> <p>Computational Approach: While traditional LLMs generate text in a fixed number of passes and are optimized for efficiency, reasoning models allocate variable computation time based on problem complexity and implement explicit \"thinking\" phases.</p> </li> <li> <p>Problem-Solving Methods: Traditional LLMs rely primarily on pattern recognition, while reasoning models utilize explicit step-by-step reasoning processes and show their work through intermediate steps.</p> </li> <li> <p>Training Methodology: Reasoning models are trained on specialized datasets focused on reasoning tasks and use reinforcement learning with rewards specifically for reasoning quality.</p> </li> <li> <p>Output Characteristics: Reasoning models produce more structured, methodical responses with explicit verification steps and self-critique, prioritizing logical correctness over natural-sounding language.</p> </li> <li> <p>Chain of Thought (CoT) Processing: Models like o1 and DeepSeek R1 implement extensive chain-of-thought reasoning, breaking down complex problems into manageable steps before providing answers.</p> </li> </ul> <p>The way I like to think about them for the purpose of building stuff with them is this: </p> <p>It's a model that gives you almost guaranteed better performance at the expense of latency and cost.</p> <p>So it's essentially a better yet slower model. </p> <p>I think looking at it from this perspective will help us define a framework for thinking about them effectively.</p>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#how-do-we-know-theyre-better","title":"How do we Know they're Better?","text":"<p>Well, if you go to  Artificial Analysis  and check out their independent evaluation of different models, you will see that their performance against other models for different indexes of capabilities like intelligence (performance in intelligence related tasks) almost always come out on top.</p> <p>According to recent benchmarks, reasoning models consistently outperform traditional LLMs on tasks requiring complex logical thinking, mathematical problem-solving, and coding challenges. For example, DeepSeek R1 has demonstrated superior performance on mathematical reasoning compared to many general-purpose models, while Claude 3.7 Sonnet with extended thinking enabled shows remarkable improvements over its standard mode.</p> <p>The performance gap is particularly noticeable in: - Complex mathematical problems - Multi-step logical puzzles - Detailed code generation with explanations - Step-by-step problem-solving in scientific domains</p> <p>However, it's worth noting that this superior performance comes with trade-offs in speed and computational cost, which I'll discuss later.</p>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#which-models-we-can-officially-call-reasoning-models","title":"Which Models we can officially call Reasoning Models?","text":"<p>Let's make a little list of the current leading reasoning models:</p> <ol> <li>Deep Seek R1 - An open-source 671B parameter model that excels in mathematical reasoning and has distilled versions available</li> <li>OpenAI o-series models - Including o1, o1-mini, o1-pro, o3-mini, and o3-mini-high, specifically designed for extended reasoning</li> <li>Claude 3.7 Sonnet - With \"extended thinking\" mode activated, becoming a hybrid reasoning/general model</li> <li>Grok-3 - xAI's latest model with enhanced reasoning capabilities</li> <li>Gemini 2.0 Flash/Advanced - Google's reasoning-focused models</li> <li>Sky T-1 - A relatively new Chinese reasoning model from SkyWork</li> <li>Baidu's ERNIE 4.0-Reasoning - Launched in March 2025 as a competitor to DeepSeek R1</li> <li>Tencent's T1 - A reasoning model introduced in early 2025</li> <li>Llama-3-70B-Instruct - While not explicitly marketed as a reasoning model, it shows strong reasoning capabilities</li> </ol> <p>This list is continually growing as more companies release specialized reasoning models to compete in this rapidly evolving space.</p>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#when-should-you-use-reasoning-models","title":"When Should You Use Reasoning Models?","text":"<p>Reasoning models shine in specific scenarios, but they're not always the right choice. Here's my take on when they make sense:</p>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#1-complex-problem-solving","title":"1. Complex Problem-Solving","text":"<p>If your use case involves solving intricate problems that require breaking down complex logic into steps, reasoning models are your best bet. They excel at:</p> <ul> <li>Mathematical challenges</li> <li>Logic puzzles</li> <li>Scientific reasoning</li> <li>Step-by-step explanations</li> </ul>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#2-code-generation-and-analysis","title":"2. Code Generation and Analysis","text":"<p>For software development tasks requiring thoughtful analysis, reasoning models offer significant advantages:</p> <ul> <li>Writing complex algorithms</li> <li>Debugging with systematic approaches</li> <li>Explaining code behavior comprehensively</li> <li>Architecture design with logical justification</li> </ul>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#3-high-stakes-decision-support","title":"3. High-Stakes Decision Support","text":"<p>When accuracy and reliability are paramount:</p> <ul> <li>Financial analysis where errors could be costly</li> <li>Medical reasoning requiring careful consideration</li> <li>Legal analysis with logical chains of thought</li> <li>Risk assessment requiring thorough evaluation</li> </ul>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#4-educational-applications","title":"4. Educational Applications","text":"<p>For tools designed to teach or explain complex topics:</p> <ul> <li>Tutorial systems requiring step-by-step instruction</li> <li>Math problem solving with shown work</li> <li>Scientific concept explanations</li> <li>Knowledge exploration with logical connections</li> </ul>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#when-traditional-llms-might-be-better","title":"When Traditional LLMs Might Be Better","text":"<p>Despite their impressive capabilities, reasoning models aren't always the optimal choice:</p> <ol> <li>Speed-Critical Applications: When response time matters more than deep thinking</li> <li>Creative Content Generation: For stories, marketing copy, or creative writing</li> <li>Casual Conversation: When natural dialogue flow is more important than rigorous logic</li> <li>High-Volume, Simple Tasks: For straightforward, repetitive tasks where the computational overhead isn't justified</li> </ol>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#the-performance-latency-trade-off","title":"The Performance-Latency Trade-off","text":"<p>This is perhaps the most critical consideration when deciding whether to implement reasoning models. They typically:</p> <ul> <li>Take significantly longer to respond (sometimes 5-10x longer)</li> <li>Consume more tokens (and therefore cost more)</li> <li>Require more computational resources</li> <li>Provide more thorough, accurate results for complex problems</li> </ul> <p>In my experience, this trade-off means you should be selective about when to deploy reasoning capabilities. For many applications, a hybrid approach works best:</p> <ul> <li>Use standard LLMs for straightforward queries and initial interactions</li> <li>Switch to reasoning modes for complex questions</li> <li>Allow users to choose whether they want quick answers or deeper analysis</li> </ul>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#how-to-prompt-reasoning-models-effectively","title":"How to Prompt Reasoning Models Effectively","text":"<p>Interestingly, prompting reasoning models often requires a different approach than traditional LLMs. Based on OpenAI's official guidance and my own experimentation:</p> <ol> <li> <p>Keep prompts simple and direct - Contrary to what you might expect, you often don't need to explicitly tell reasoning models to \"think step by step.\" They're already designed to do this.</p> </li> <li> <p>Structure complex problems clearly - Use delimiters and clear formatting to separate different parts of your input.</p> </li> <li> <p>For mathematical or logical problems, provide:</p> </li> <li>Clear problem statements</li> <li>Relevant context</li> <li> <p>Expected output format</p> </li> <li> <p>Model-specific considerations:</p> </li> <li>For OpenAI's o-series, \"developer messages\" replace traditional system messages</li> <li>Claude 3.7 Sonnet requires explicit activation of extended thinking mode</li> <li> <p>DeepSeek R1 excels with mathematical reasoning when given clean, well-structured problems</p> </li> <li> <p>Use verification steps for critical applications - Ask the model to verify its own work when accuracy is paramount.</p> </li> </ol>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#implementation-considerations","title":"Implementation Considerations","text":"<p>If you're planning to implement reasoning models in your applications, consider these practical factors:</p>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#1-cost-management","title":"1. Cost Management","text":"<p>Reasoning models typically: - Process more tokens per request - Take longer to generate responses - May require premium API access</p> <p>Implement strategies like: - Selective use for complex queries only - Caching common reasoning patterns - User-controlled access to reasoning capabilities</p>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#2-latency-handling","title":"2. Latency Handling","text":"<p>The extended processing time requires thoughtful UX design: - Implement streaming for progressive response display - Show intermediate reasoning steps as they're generated - Provide clear user expectations about response times</p>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#3-hybrid-architectures","title":"3. Hybrid Architectures","text":"<p>Consider architectures that combine: - Traditional LLMs for routine queries - Reasoning models for complex problems - Distilled reasoning models as a middle ground - Human review for critical applications</p>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#4-the-role-of-distilled-models","title":"4. The Role of Distilled Models","text":"<p>An exciting development is the emergence of distilled reasoning models like DeepSeek-R1-Distill-Qwen-32B, which: - Retain 80-95% of the reasoning capabilities of larger models - Run on more modest hardware - Offer faster inference times - Provide a cost-effective middle ground</p> <p>For many practical applications, these distilled models hit the sweet spot between performance and efficiency.</p>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#the-future-of-reasoning-models","title":"The Future of Reasoning Models","text":"<p>We're just at the beginning of the reasoning model era, and I expect rapid developments:</p> <ul> <li>More efficient reasoning approaches that reduce latency</li> <li>Specialized reasoning models for specific domains (medical, legal, financial)</li> <li>Improved distillation techniques preserving more reasoning capabilities</li> <li>Better integration of reasoning with multimodal capabilities</li> </ul> <p>The competition between open-source models like DeepSeek R1 and proprietary offerings like OpenAI's o-series is driving innovation at a remarkable pace, with the performance gap between them narrowing significantly.</p>"},{"location":"posts/2025-03-23-reasoning-models%2C-when-to-use-them%3F-what-are-they-good-for%3F/#conclusion","title":"Conclusion","text":"<p>Reasoning models represent a significant advancement in AI capabilities, offering new possibilities for applications requiring thoughtful, methodical problem-solving. They're not a replacement for traditional LLMs but rather a specialized tool for specific use cases where depth of thinking matters more than speed.</p> <p>When implementing them, focus on: 1. Selecting the right use cases where their advantages justify the trade-offs 2. Designing user experiences that manage expectations around response times 3. Considering hybrid approaches that leverage different model types appropriately 4. Exploring distilled models as a balanced option for many applications</p> <p>As these models continue to evolve, they'll enable increasingly sophisticated applications that tackle problems previously beyond the reach of AI systems. The key is understanding their unique characteristics and implementing them thoughtfully where they add the most value.</p> <p>What are your experiences with reasoning models? Have you found particular applications where they shine? Let me know in the comments below!</p>"},{"location":"posts/2025-04-10-agents-planning-eval-ai-index-reports/","title":"Agents, Planning, Evaluation and AI Index Reports 2025","text":"<p>I recently compiled a reading list of a few articles, reports and interesting content to read as a single .pdf.</p> <p>The highlights of this read were:</p> <ol> <li>Agents by Chip Huyen</li> <li>A State of AI Report by McKinsey</li> <li>The Anthropic Economic Index for Claude 3.7 Sonnet</li> <li>Anthropic Education Report: How University Students Use Claude</li> <li>Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences</li> </ol> <p>If you want the full list of reads check out the compilation pdf I put up here:</p> <p>Download the full compilation here</p> <p>Now, I want to write about the main insights from this read.</p>"},{"location":"posts/2025-04-10-agents-planning-eval-ai-index-reports/#planning-failures-evaluation-and-tool-selection-tips","title":"Planning Failures, Evaluation and Tool Selection Tips","text":"<p>In Huyen's amazing piece she oulines a few things that for me are not obvious when it comes to thinking about agents, those are modes of planning failures in agents and tips for selecting tools.</p>"},{"location":"posts/2025-04-10-agents-planning-eval-ai-index-reports/#planning-failures","title":"Planning Failures","text":"<p>Agents might fail in the following way:</p> <ol> <li>Invalid tool - where the agent generates a plan with a tool that is not available.</li> <li>Valid tool but invalid parameters - the agent generates a plan with an appropriate tool but it gives parameters to it in the wrong way (like the tool might accept 2 parameters and the agent gives it one).</li> <li>Valid tool but invalid parameter values - Same as before but in this case the agent gives the right amount and type of parameters but these are just the incorrect values.</li> <li>Goal failure - the agent might miss the task all together or not abive by the requirements properly. </li> </ol> <p>Interesting points about goal failure: a. Taking too long - that sometimes the agent might solve a task, but it might take so long that this latency in itself is a failure (like missing a deadline). b. Reflection failure - when the agent thinks it solved the task when it hasn't</p>"},{"location":"posts/2025-04-10-agents-planning-eval-ai-index-reports/#evaluation-for-planning-failures","title":"Evaluation for Planning Failures","text":"<p>To evaluate for planning failures one could generate a planning dataset where each example is a pair of task and tool inventory, where for each task the agent is used to generate a certain number of plans and then compute some interesting metrics:</p> <ol> <li>Out of all generated plans, how many are valid?</li> <li>For a given task, how many plans does the agent have to generate to get a valid plan?</li> <li>Out of all tool calls, how many are valid?</li> <li>How often are invalid tools called?</li> <li>How often are valid tools called with invalid parameters?</li> <li>How often are valid tools called with incorrect parameter values?</li> </ol> <p>All of those attempt to find the quantifiable elements of this subjective problem of measuring performance for the planning capabilities of an agent. </p> <p>The idea here being that, when you analyze the agen'ts outputs for patterns you should look at things like: \"What types of tasks does the agent fail more on?\", any hypothesis as to why?. What tools does it fail more often?. </p> <p>One can improve an agent's ability to use hard tools by improving upon:</p> <ol> <li>Prompting</li> <li>Giving it more examples</li> <li>Fine-tuning</li> </ol>"},{"location":"posts/2025-04-10-agents-planning-eval-ai-index-reports/#tool-selection-tips","title":"Tool Selection Tips","text":"<p>Chip Huyen's article gives these 4 cool tips for tool selection:</p> <p></p>"},{"location":"posts/2025-04-10-agents-planning-eval-ai-index-reports/#insights-from-evalgen-paper","title":"Insights from EvalGen Paper","text":"<p>Luckly enough, despite my reading list being a somewhat random compilation of materials, I accidently put together 2 quite relevant reads back to back, Chip Huyen's Agent article and this really cool 2024 paper: \"Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences\". </p> <p>This paper is interesting because it takes on the challenge of looking at the subjective nature of \"criteria\" when addresssing LLM evaluation. They talk about this concept of \"criteria drift\" where when users face llm outputs that changes and refines the criteria for evaluating them altogether. </p> <p>To me it's interesting this idea that reviewing LLM outputs changes what users think the evaluation criteria should be. I guess it makes sense to think about criteria for what is a good output to be something dynamic and iterative rather than a rigid/written in stone definition.</p> <p>From my ChatGPT conversations about this paper we came up with these insights from the paper:</p> EvalGen Paper Insights <ol> <li> <p>\ud83d\udd01 Evaluation Criteria Evolution</p> <p>Core Finding: Evaluation criteria are dynamic, not static. They evolve as reviewers encounter more LLM outputs.</p> <p>Implication: Build evaluation systems that support iterative refinement. Initial rubrics should be treated as starting points, not final standards. Expect early review cycles to reshape your understanding of quality.</p> </li> <li> <p>\ud83e\udde0 Human Standards Development</p> <p>Core Finding: Humans develop evaluation norms through the review process itself.</p> <p>Implication: Design validation workflows (e.g., reflection agents, human-in-the-loop scoring) with calibration periods. Enable reviewers to co-develop standards rather than enforcing rigid rubrics from the start.</p> </li> <li> <p>\ud83d\udd0d Output-Influenced Judgment</p> <p>Core Finding: LLM outputs directly influence how validators assess quality.</p> <p>Implication: Be mindful of feedback loops where validator criteria adapt to model behavior rather than external standards. Monitor for potential reinforcement of model quirks.</p> </li> <li> <p>\ud83e\udded Transparency Over Consensus</p> <p>Core Finding: Task interpretation evolves through discussion, not just through right/wrong determinations.</p> <p>Implication: In multi-agent systems, prioritize surfacing reasoning and disagreements over achieving consensus. Build mechanisms to track why decisions are made.</p> </li> <li> <p>\ud83d\udcca Tracking Subjectivity</p> <p>Core Finding: Evaluation inherently involves subjective judgment without absolute ground truth.</p> <p>Implication: Implement meta-evaluation tools (e.g., rationale recording, agent reflection prompts) to make subjectivity traceable and transparent.</p> </li> </ol>"},{"location":"posts/2025-04-10-agents-planning-eval-ai-index-reports/#insights-from-anthropics-claude-37-sonnet-economic-index","title":"Insights from Anthropics Claude 3.7 Sonnet Economic Index","text":"<p>Anthropic has been putting out some awesome reports on AI usage. A recent one that was on my reading list for way too long was this:</p> <p>Anthropic Economic Index: Insights from Claude Sonnet 3.7</p> <p>In it they outline how different occupations use Claude 3.7 Sonnet and its new extended thinking mode.</p> <p>The highlights of this article for me were:</p> <p>Increase in usage share for math/coding and education but a decrease for arts and media! </p> <p>I think this decrease might relate to copywright infringement laws and overall distrust with big tech companies.</p> <p> Image taken from: Anthropic Economic Index: Insights from Claude Sonnet 3.7 </p> <p>Increase in learning usage (a type categorized as augmentation) but also an increase in directive usage (when you ask for what you want directly) in the automation group + a decrease in task iteration</p> <p> Image taken from: Anthropic Economic Index: Insights from Claude Sonnet 3.7 </p> <p>In my head this could be explained as:</p> <pre><code>a. Increase in learning usage because people are learning about the powers of models now and starting to use it (I know so many people that don't use the top models and think we are still in 2022...)\n\nb. Increase in directive usage might be a mix of people getting lazier and trusting more the powerful models coming out\n\nc. Decrease in task iteration I associate with the overall improvement in the quality of the models as a whole\n</code></pre> <p>IT people use it the most for feedback loops (no surprises here...)</p> <p>Copy writers and editors use it the most for task iteration - I thought software engineers were going to win this one...</p> <p>Most occupations are using AI in only a small share of their tasks.</p> <p> Image taken from: Anthropic Economic Index: Insights from Claude Sonnet 3.7 </p> <p>I had to double check with ChatGPT this one, but in this graph they coined \"depth of task usage\" they plot the minimum fraction of tasks in use on the x-axis and the % of occupations on the y-axis, showing that AI usage is still reserved for a small share of tasks across most occupations, which I think is a mix of being early still and the adaptation to this new worklow takes some adjustment.</p>"},{"location":"posts/intuitive-introduction-to-langgraph/","title":"Intuitive introduction to langgraph","text":"<p>article--- title: An Intuitive Introduction to LangGraph date: 2025-02-10</p>"},{"location":"posts/intuitive-introduction-to-langgraph/#an-intuitive-introduction-to-langgraph","title":"An Intuitive Introduction to LangGraph","text":""},{"location":"posts/intuitive-introduction-to-langgraph/#routing-stuff","title":"Routing Stuff","text":"<p>I'm working on my LangGraph course and I kind of wanted to do a little recap of how I see this framework in the big scheme of things.</p> <p>When working with LLMs, one common pattern that exists is to route stuff, meaning you send some input to an LLM and the output of that gets routed to either another LLM as described in this article by Anthropic about common patterns for working with LLMs or even to some other functionality like you might use some Python function to clean the output of that LLM.  </p> <p></p> <p>This is great because the LLM has some type of understanding of what is going on even though we still don't really understand the nature of this understanding, however it is good enough that we can actually use it to make some processing pipeline a bit leaner by having LLMs make certain decisions within some narrow scopes of a workflow.</p>"},{"location":"posts/intuitive-introduction-to-langgraph/#the-abstraction-challenge","title":"The Abstraction Challenge","text":"<p>Now, if I am writing up a system that can perform complex tasks, </p> What do I mean by complex? <p>Integration of a diverse set of components that do all sorts of different things like performing actions, calling apis, processing massive amounts of diverse data like text and images, and so on.</p> <p>it is a bit problematic to implement it just as simple calls to apis like OpenAI or Anthropic's, because we want that system to be pragmatically improvable (robust, consistent). </p> <p>What I mean is that despite wanting the flexibility brought by LLMs, we also want the controllability offered by writing software that does stuff deterministically and can be systematically improved over time.</p> <p>So that begs the question of how we create useful abstractions around the capabilities of Large Language Models? </p> <p>To understand that, we need to understand what we are trying to abstract, for that, let's take the most common pattern in this emerging field of Agents that is growing quite a bit this year: React Agent.</p> <p></p> <p>What is there to abstract?</p> <p>Well, a bunch of stuff, if want to be able to develop a system aroud these things we need to be able to abtract things like:</p> <ol> <li>Messaging between user and LLM apis</li> <li>Calling LLM apis</li> <li>Integrating tools into LLMs as functions that call external APIs</li> </ol> <p>and much more (see diagram below).</p> <p></p> <p>Not only that, but we also want to be able to track and monitor these parts so that when problems occured we can investigate what happen and debug our system across all of its parts.</p>"},{"location":"posts/intuitive-introduction-to-langgraph/#langchain","title":"LangChain","text":"<p>LangChain came into the scene as a framework that allowed you to put all these different parts that are common when building LLM apps, into the same 'system'. </p> <p>In LangChain everything is a runnable, which means, things like calling an LLM, calling a tool that performs some action, the prompt that you send to the model, and many other things like that become all components in this runnable interface that can be organized via the usage of a declarative language called LCEL (LangChain Expression Language).</p> <p>The idea is that you can create <code>chains</code> which in LangChain are building blocks made out of the component parts like <code>prompt template</code> <code>chat models</code> and many others, in order to create modular workflows that have swappable parts.</p> <p></p> <p>LangChain became extremely popular I think in part because they were the first to realize that there was much more value to be extracted from LLMs than just asking them for text and getting results back, building on top of super important papers that started to explore these additional functionalities like:</p> <ul> <li>Toolformer: Language Models Can Teach Themselves to Use Tools</li> <li>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</li> <li>ReAct: Synergizing Reasoning and Acting in Language Models</li> </ul> <p>However, building this framework came at the cost of having to make choices for how the infrastructure around LLMs should look like, which is not a trivial problem because we are talking about a technology in its infancy, consider that ChatGPT was released in 2022!</p>"},{"location":"posts/intuitive-introduction-to-langgraph/#langgraph","title":"LangGraph","text":"<p>Regardless of what the ultimate abstraction for LLMs look like, what we know right now is that there are common patterns for using it, which usually involve taking some input and passing it through a set of transformations, some of which are handled by LLMs (so not completely deterministic) and some are handled by normal code.</p> <p>What the LangChain folks realized is that most of what we do with LLMs could actually be handled by treating the entire process as graphs with nodes and edges to integrate controllability into the system while mixing it with the flexible nature of LLMs.</p> <p>So LangGraph was born.</p> <p>The way I look at it, LangChain gives you the material to do the basics with LLMs like:</p> <ul> <li>Call LLM APIs</li> <li>Integrate Prompts</li> <li>Loading documents</li> <li>Tools, retrievers for rag systems</li> <li>....</li> </ul> <p>however, when it comes to putting together a system, connecting different things and managing all of that, the LCEL comes short of something simple and intuitive that can give you manageable complexity and controlability.</p> <p>So LangGraph shows up as a framework that can take in the standardization provided by operating on LangChain Components, and provide the graph building capabilities that are considerably more intuitive when compared to 'chaining runnables'.</p> <p></p> <p>In LangGraph you introduce cycles into these chains, in the form of 'controlled flows' or 'state machines':</p> <p>LangGraph is a way to create these state machines by specifying them as graphs.</p>"},{"location":"posts/intuitive-introduction-to-langgraph/#what-do-we-get-with-graphs","title":"What Do we Get with Graphs?","text":""},{"location":"posts/intuitive-introduction-to-langgraph/#states-nodes-edges","title":"States, Nodes &amp; Edges","text":"<p>In LangGraph the logic is to define some initial 'state' which is a data structure that will be updated throughout the execution of the graph.</p> <p>Let's take this diagram we showed of the simple react agent loop, where we have some input coming in to a model connected to some tools, and the model is going to go on a loop of calling said tools until a response is generated.</p> <p>For something like that we would need to define:</p> <ol> <li>The LLM to use</li> <li>The tools that model has access to</li> <li>Connect LLM to the tools (so the model can create the arguments for it)</li> </ol> <pre><code>from langchain_community.tools import TavilySearchResults \nfrom langchain_anthropic import ChatAnthropic\n\n# The LLM\nllm = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n# The tool (for web search)\nsearch_tool = TavilySearchResults()\n# Connect LLM to tool \nllm_with_tools = llm.bind_tools([search_tool])\n</code></pre> <p>Now, we need to take this core set of functionality we've built and inserted in a graph. To do so we need:</p> <ol> <li>To define a state</li> <li>Nodes (that perform the computations)</li> <li>Edges (that connect everything together)</li> </ol> <p>The state will define this updatable data structure that will change throughout the execution of the graph. The nodes will be the functions that perform the computations that happen throughout this graph like running LLM calls, using the tools and so on.</p> <p>The edges will join all the nodes together defining the direction of this graph.</p> <p>We start by defining the nodes as simple python functions:</p> <pre><code># The node where the LLM+tools is called\ndef llm_node(state: MessagesState):\n    # Gets the latest message in the messages list\n    response = llm_with_tools.invoke(state[\"messages\"])\n    print(\"response\")\n    print(response)\n    # returns a dictionary that corresponds to updating the state\n    # adding a the message from the model's response\n    return {\"messages\": [response]}\n\n# The node that performs the conditional logic that defines whether the\n# LLM will call a tool and return a final output to the user \ndef router_node(state: MessagesState):\n    if state[\"messages\"][-1].tool_calls:\n        # routes to a node called: \"tools\"\n        return \"tools\"\n\n    # if there is no action required, we end the loop\n    return END\n</code></pre> <p>NOw that we have the nodes as python functions, we can define our graph.  We start by defining the initial state as a <code>MessagesState</code> object, which means its a data structure that contains a default list of messages inside + the ability to add more messages to this list as the graph get's executed.</p> <pre><code>builder = StateGraph(MessagesState)\n</code></pre> <p>We integrate the nodes we've created earlier: <pre><code>builder.add_node(\"llm\", llm_node)\nbuilder.add_node(\"tools\", tool_node)\n</code></pre></p> <p>We set an entry point for the graph <pre><code># we set the entry point for the graph to be the llm\n# which means the user will send the input directly to the LLM\nbuilder.add_edge(START, \"llm\")\n</code></pre> Connect the llm to the function containing the conditional logic that routes information either to the user (END) or to the node containing the tools, and compile the graph.</p> <pre><code>builder.add_conditional_edges(\"llm\", router_node, [\"tools\", END])\n# Here we make it so that the output of the tools node has to go to the \"llm\"\nbuilder.add_edge(\"tools\", \"llm\")\n\ngraph = builder.compile()\n</code></pre> <p>Great! Now we can see how it looks!</p> <p><pre><code>try:\n    display(Image(graph.get_graph().draw_mermaid_png()))\nexcept Exception:\n    # This requires some extra dependencies and is optional\n    print(\"Did not display graph\")\n    pass\n</code></pre> </p> <p>Looks pretty simple right? But now, we can actually have it look up information online and return written results!</p> <pre><code>graph.invoke(\n    {\n        \"messages\": [\"human\", \"Search online for current AI conferences happening in Silicon Valley right now.\"]\n    }\n)\n</code></pre> <p>There are many other core concepts in LangGraph such as:</p> <ul> <li>Persistence &amp; Memory</li> <li>Subgraphs</li> <li>Configuration</li> <li>Command</li> <li>....</li> </ul> <p>We'll leave that for another article! :)</p> <p>Cheers!</p> <p>Subscribe to my Newsletter</p>"},{"location":"posts/llm-usage-general-tips/","title":"Quick Tips on Using LLMs Effectively","text":"<p>All right, this is going to be my own attempt at compiling some fun examples of how to prompt LLM models effectively to do useful stuff.</p>"},{"location":"posts/llm-usage-general-tips/#prompt-iteratively","title":"Prompt Iteratively","text":"<p>I think it was Jeremy Howard who coined this term 'Dialog Engineering' where you build and engineer things through talking to an LLM in small steps.</p> <p>This could not be more true. Prompt atomically, for example: instead of asking a model to build a 'quiz app' maybe ask the model to:</p> <ol> <li>\"Design a basic data structure for quiz questions and answers\"</li> <li>\"Create a function to load and parse quiz questions from a JSON file\" </li> <li>\"Build a simple command-line interface to display questions and accept user input\"</li> <li>\"Add scoring logic to track correct/incorrect answers\"</li> <li>\"Implement a way to save quiz results and show final score\"</li> </ol> <p>Something like that where you prompt in small pieces and for each you supervise the result and incrementally grow into the final result you were looking for.</p> <p>This is a perfect segway to my next tip.</p>"},{"location":"posts/llm-usage-general-tips/#use-llms-as-assistants-not-as-replacements","title":"Use LLMs as assistants not as replacements","text":"<p>Don't treat whatever is generated with an AI as the final all might output. Treat everything you get from it critically, which I know can sound a bit contradictory given the nature of why we are using LLMs right? We are using it so we don't have to do the work. However, this approach can only lead to hours of mindless debugging and absolute dread. </p> <p>Instead, treat the model like the great Simon Willison puts it in this youtube video where he mentions you should treat them as \"smart interns\" that \"read through all the documentation\" and can help 24/7.</p> <p>I think you should use them as supporting like tools to support support the decisions that you're making... - Simon Willison </p>"},{"location":"posts/llm-usage-general-tips/#ask-for-multiple-options","title":"Ask for Multiple Options","text":"<p>Specially for tought questions, don't ask the models for one answer, ask for many and pick the ones that looks best.</p>"},{"location":"posts/llm-usage-general-tips/#use-it-to-explore-and-not-just-for-quick-answers","title":"Use it to Explore and Not Just for Quick Answers","text":"<p>Do side projects with these tools and explore what they can do instead of  relying on them just as a google search replacement.</p>"},{"location":"posts/llm-usage-general-tips/#explore-and-experiment","title":"Explore and Experiment","text":"<p>When working with AI tools, it's important to approach them with a spirit of exploration and experimentation rather than just using them for quick answers. Here are some key ways to do this:</p> <p>Challenge yourself to do complete projects using AI tools. As one developer put it: \"If you can afford to do a side project with these tools and like set yourself a challenge to write every line of code with these tools, I think that's a great thing you can do.\"</p>"},{"location":"posts/patterns-for-llm-usage/","title":"Patterns for Effective Usage of LLMs","text":""},{"location":"posts/patterns-for-llm-usage/#code-generation","title":"Code Generation","text":"<p>Paste code + error ask it to debug</p> <p>Copy paste from ChatGPT/Claude/Gemini/Llama3 and also paste in error + original code to get better answer.</p> <p>Automate Cleaning AI Output</p> <p>Setup a quick tool to clean up the Python code generated (I use an alias <code>clean-python</code>)</p> <p>Use Standalone Scripts with AI + uv</p> <p>Generate Python standalone scripts by using Claude+Projects with custom descriptions and the uv package manager</p> <p>Leverage Context</p> <p>For recent coding frameworks use the documentation as json/markdown files as context for something like Claude/ChatGPT projects. Show LLM how to call an API (in the prompt) then ask it to create something with that api.</p>"},{"location":"posts/patterns-for-llm-usage/#general-usage","title":"General Usage","text":"<p>Let it see your screen</p> <p>Use tools like Gemini 2.0 with streaming in realtime in Google AI Studio so the AI can see your screen to help you navigate new software and answer app specific questions in context.</p> <p>Save your AI Mistakes</p> <p>When AI makes a mistake save it for later as your own personal benchmark</p> <p>Build Micro-AI-Powered Data Transformation Pipelines</p> <p>Build app with AI that takes in data with a certain structure and outputs  desirable output, format, etc.... then make a prompt template that  produces the data into the format acceptable  by that app (done).  </p> <p>Conceptual Knowledge Prompting</p> <p>When creating knowledge management prompts (like for Anki cards), structure them around these 5 key dimensions: - Attributes &amp; tendencies - Similarities and differences - Parts &amp; Wholes - Causes &amp; Effects - Significance &amp; Implications</p> <p>This helps move beyond simple memorization towards deeper encoding of knowledge.</p> <p>Background AI Assistance</p> <p>Run lighter models (Tier 3) in the background to provide gentle guidance without disrupting workflow. For example: - Watching note creation to suggest knowledge structuring patterns - Using SuperWhisper to transform free-form thinking into structured content - Converting audio brainstorming into written documentation</p>"},{"location":"posts/patterns-for-llm-usage/#patterns-for-prompt-templates","title":"Patterns for Prompt Templates","text":"<p>Informed transformation </p> <pre><code>Given this {{ context }}. Do {{ action }} to this {{ content }}.\n</code></pre> <p>The OUTPUT ONLY Pattern</p> <p>Prime model at the very end to: </p> <p><code>(...previous context...) OUTPUT ONLY {{ desired output }}</code></p> <p>Use Meta Prompts</p> <p>Use prompts for prompts! Create a prompt that uses a model to  generate multiple prompts that address all the parts of your task.</p> <p></p> <p>For example:</p> <pre><code>I need to create a series of prompts to help me analyze customer feedback data. \nPlease generate 3 prompts for an LLM model to help me:\n\n1. Extract key themes and sentiment\n2. Identify urgent issues needing attention\n3. Generate actionable insights for product improvements\n\nFor each prompt you generate, explain its purpose and expected output format.\n\nOUTPUT ONLY the prompts and their explanations, formatted as such:\nPURPOSE: &lt;purpose of prompt&gt;\nInstruction: &lt;main instruction&gt;\nOUTPUT FORMAT: &lt;desired output format&gt;\n</code></pre> <p>You can also ask the model to break down the problem itself given some  initial goal or intention and then for each sub-task ask for a solution:</p>"},{"location":"posts/patterns-for-llm-usage/#which-models-to-use-when","title":"Which Models to Use When","text":""},{"location":"posts/patterns-for-llm-usage/#model-tiers","title":"Model Tiers","text":""},{"location":"posts/patterns-for-llm-usage/#tier-1-high-intelligence-slow-expensive","title":"Tier 1 (High Intelligence, Slow, Expensive)","text":"<ul> <li>For complex, nuanced tasks</li> <li>Examples: DeepSeek, O1.  </li> </ul>"},{"location":"posts/patterns-for-llm-usage/#tier-2-balanced","title":"Tier 2 (Balanced)","text":"<ul> <li>It is your daily driver for most tasks \u2013 code, emails, general queries</li> <li>Examples: GPT-4o, Claude 3.5 Sonnet, Gemini 1.5 Pro, Llama 3.3.</li> </ul>"},{"location":"posts/patterns-for-llm-usage/#tier-3-cheap-fast","title":"Tier 3 (Cheap, Fast)","text":"<ul> <li>For bulk, everyday tasks</li> <li>Examples: GPT-4o-mini, Gemini Flash, Llama 3.\u2153.2.</li> <li>Enables AI usage in \"every nook and cranny\"</li> </ul>"},{"location":"posts/patterns-for-llm-usage/#workflow-example","title":"Workflow Example","text":"<ol> <li>Use Tier 3 to process large documents quickly and cheaply</li> <li>Use Tier 2 to refine and apply structured outputs</li> <li>Use Tier 1 for final critical reasoning or complex synthesis</li> </ol>"}]}