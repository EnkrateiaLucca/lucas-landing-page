---

title: Notes on the Latest Regarding AI Tools
date: 2025-10-22

# Notes on the Latest Regarding AI Tools
---

# Cool Stuff I read over the past month

<!-- more -->

## LLMs as Dangerous Lossy Compressions

- [LLM as a lossy encylopedia analogy](https://simonwillison.net/2025/Aug/29/lossy-encyclopedia/)
  - Don't expect LLMs to have knowledge of specific facts, expect them to be able to act on facts that are shown.

In the words of Simon Willison:
> treat it as a tool that can act on facts presented to it.

- This analogy combines perfectly with this [idea of ChatGPT as a sort of lossy jpeg of the web's knowledge](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web#:~:text=What%20I%E2%80%99ve%20described,look%20less%20sharp.) with the added factor that because the output is in text the 'bluriness' of it's content is not immediately recognizable
  - [This analogy however dismissive can be used to minimize people's tendency to anthropomorphize LLMs like ChatGPT](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web#:~:text=useful%20corrective%20to%20the%20tendency%20to%20anthropomorphize%20large%20language%20models)
  - [There are bluriness that are acceptable when one restates the same thing with different words, and then bluriness that masks hallucination which is dangerous](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web#:~:text=There%E2%80%99s%20a%20type,the%20near%20future.)
  - [Compression seems to be some sort of tool to reaching through AI because the greatest level of it involves understanding the text](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web#:~:text=hutter%20believes%20that%20better%20text%20compression%20will%20be%20instrumental%20in%20the%20creation%20of%20human-level%20artificial%20intelligence%2C%20in%20part%20because%20the%20greatest%20degree%20of%20compression%20can%20be%20achieved%20by%20understanding%20the%20text.)
    - An example of that is a [calculator which through enforcing the rules of arithmetics, can 'compress' infinite examples in a file containing math operations and so on.](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web#:~:text=Using%20a%20calculator%2C%20you%20could%20perfectly%20reconstruct%20not%20just%20the%20million%20examples%20in%20the%20file%20but%20any%20other%20example%20of%20arithmetic%20that%20you%20might%20encounter%20in%20the%20future.)
      - This same logic would apply to knowledge of the web compressed into a slice of wikipedia, the more one knows about a topic, the more words it can remove from a wikipedia page because it can easily reconstruct it.
  - [Funny enough, when it comes to language, lossy compression seems smarter that lossless because it gives the impression that the person speaking actually understood the materia rather than regurgitating the source](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web#:~:text=when%20we%E2%80%99re%20dealing%20with%20sequences%20of%20words%2C%20lossy%20compression%20looks%20smarter%20than%20lossless%20compression.)

> [The rise of this type of repackaging is what makes it harder for us to find what weâ€™re looking for online right now; the more that text generated by large language models gets published on the Web, the more the Web becomes a blurrier version of itself.](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web#:~:text=the%20rise%20of%20this%20type%20of%20repackaging%20is%20what%20makes%20it%20harder%20for%20us%20to%20find%20what%20we%E2%80%99re%20looking%20for%20online%20right%20now%3B%20the%20more%20that%20text%20generated%20by%20large%20language%20models%20gets%20published%20on%20the%20web%2C%20the%20more%20the%20web%20becomes%20a%20blurrier%20version%20of%20itself.)

## Context Engineering Notes

- [Andrej Karpathy's tweet about context engineering](https://x.com/karpathy/status/1937902205765607626)

- [Definition from PhilSchmid blog:](https://www.philschmid.de/context-engineering)

> Context Engineering is the discipline of designing and building dynamic systems that provides the right information and tools, in the right format, at the right time, to give a LLM everything it needs to accomplish a task.

- The wording of context engineering is a useful abstraction for the new types of challenges involved in building useful ai based applications
- [Context engineering seems to be a craft of filling the LLM's context window](https://www.llamaindex.ai/blog/context-engineering-what-it-is-and-techniques-to-consider#:~:text=people%20associate%20prompts%20with%20short%20task%20descriptions%20you'd%20give%20an%20llm%20in%20your%20day-to-day%20use.%20when%20in%20every%20industrial-strength%20llm%20app%2C%20context%20engineering%20is%20the%20delicate%20art%20and%20science%20of%20filling%20the%20context%20window%20with%20just%20the%20right%20information%20for%20the%20next%20step.)
- Everything that goes into the 'context' of LLMs:
  - System prompt; User input; chat history; long term memory/retrieved information; Tools & definitions; Responses from tools; structured outputs; [global state/context](https://chatgpt.com/share/68f8d5d8-6a9c-8004-b0b5-078fbc117ff5)
- Context engineering is about selecting the right context and making it fit into the context window (I would also say is about managing it to keep or maintain performance at a useful level)

- [Workflow engineering is about asking the question: 'What sequence of LLM calls and non-LLM steps do we need to reliably complete this work?'](https://www.llamaindex.ai/blog/context-engineering-what-it-is-and-techniques-to-consider#:~:text=While%20context%20engineering,that%20lets%20you)


## AI as Augmentation

- [Gen AI can be a tool to support creativity but it's not creative on its own](https://arxiv.org/pdf/2505.17241)
- [Interesting term 'Cognitive Shortcut Paradox' discussing how even though AI can make a good engineer faster, the skills to become a 'good engineer' require not using it, therefore, leveraging AI at the early stages of one's development might hinder their ability to truly learn and become a good developer/programmer/engineer.](https://www.oreilly.com/radar/the-cognitive-shortcut-paradox/#:~:text=AI%20gives%20novice,gaining%20that%20experience.)
    - Quotes I liked from this article:
> - Experience builds judgement required to evaluate, debug, and improve AI-generated code. 
> - [the missing skills stay hidden until the gap is too wide to close](https://www.oreilly.com/radar/the-cognitive-shortcut-paradox/#:~:text=the%20missing%20skills%20stay%20hidden%20until%20the%20gap%20is%20too%20wide%20to%20close.)
> - [If developers turn to AI at the first sign of difficulty, they skip the work that builds the pattern recognition and systematic thinkging senior engineers depend on](https://www.oreilly.com/radar/the-cognitive-shortcut-paradox/#:~:text=if%20developers%20turn%20to%20ai%20at%20the%20first%20sign%20of%20difficulty%2C%20they%20skip%20the%20work%20that%20builds%20the%20pattern%20recognition%20and%20systematic%20thinking%20senior%20engineers%20depend%20on.)
> [The question isnt' whether to use AI in learning, but how to use it in ways that build rather than bypass the critical thinking abilities that separate effective developers from code generators.](https://www.oreilly.com/radar/the-cognitive-shortcut-paradox/#:~:text=the%20question%20isn%E2%80%99t%20whether%20to%20use%20ai%20in%20learning%2C%20but%20how%20to%20use%20it%20in%20ways%20that%20build%20rather%20than%20bypass%20the%20critical%20thinking%20abilities%20that%20separate%20effective%20developers%20from%20code%20generators.)
> 


## Claude Skills

- Agents skills are composable resources to augment agents like claude
- [A skill is a directory containing a SKILL.md file that contains organized folders of instructions, scripts, and resources that give agents additional capabilities.](https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills#:~:text=a%20skill%20is%20a%20directory%20containing%20a%20skill.md%20file%20that%20contains%20organized%20folders%20of%20instructions%2C%20scripts%2C%20and%20resources%20that%20give%20agents%20additional%20capabilities.)
- [Skills have a first level of 'progressive disclosure' which allows it to disclose just enough information to the agent so that it knows when each skills should be used without loading all of the information.](https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills#:~:text=this%20metadata%20is%20the%20first%20level%20of%20progressive%20disclosure%3A%20it%20provides%20just%20enough%20information%20for%20claude%20to%20know%20when%20each%20skill%20should%20be%20used%20without%20loading%20all%20of%20it%20into%20context.%20)
- [Skills allow you to run code and extract data from files like pdfs without loading all of that into context (nor the python script nor the pdf)](https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills#:~:text=In%20our%20example,of%20the%20task.)
- [To develop skills:](https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills#:~:text=Start%20with%20evaluation,anticipate%20it%20upfront.)
  - evaluate on recurring tasks; identify gaps of performance
  - structure splitting a big SKILL.md file into preferably mutually exclusive files (like this [forms.md file from the pdf skill](https://github.com/anthropics/skills/tree/main/document-skills/pdf))
  -  Skills [docs](https://docs.claude.com/en/docs/agents-and-tools/agent-skills/overview) and [cookbook](https://github.com/anthropics/claude-cookbooks/tree/main/skills)
  
## Agentic Engineering
- Concept of ['blast radius'](https://steipete.me/posts/just-talk-to-it#:~:text=Whenever%20I%20work,sth%20goes%20wrong.) which is like the extend of the influence of a code modification done by some AI agent
- Interestingly this developer [does not use git worktrees](https://steipete.me/posts/just-talk-to-it#:~:text=Why%20not%20worktrees,about%20Claude%20Code%3F), an approach that has seen some [popularity among aclaimed AI devs like Simon Willison](https://simonwillison.net/2025/Oct/5/parallel-coding-agents/)
  - [Here is how to use git worktrees with claude code](https://docs.claude.com/en/docs/claude-code/common-workflows#run-parallel-claude-code-sessions-with-git-worktrees)
- [Claude Code has more features but this dev argues for why Codex is a better coding agent, arguments involve: bigger ctx window, more efficient token usage, message queuing, faster and codex seems to be better at understanding language according to him](https://steipete.me/posts/just-talk-to-it#:~:text=What%20about%20Claude,Why%20not%20%24harness)
- [Cool visual](https://steipete.me/posts/just-talk-to-it#:~:text=just%20talk%20to%20it%20-%20the%20no-bs%20way%20of%20agentic%20engineering) shared by the author shows that the optimal balance between complexity and time spent writing to the coding agent seems to involve:
    - Using 8 agents at same time
    - complex orchestration with multiple checkouts
    - chaining agents together
    - custom subagent workflows
    - library of 18 different slash commands
    - large full-stack features